# 대량 상품 출고 데이터 처리

2023년도 3-4분기 물류팀에 있을때 경험했던 대량 출고 데이터 처리 효율화에 대한 이야기를 적어보려고 합니다.

- 참고: 케타포의 시스템은 크게보면 물류와 커머스로 나누어져 있습니다.
<p align="center"><img src="https://github.com/ejoongseok/blog/assets/99948743/a46ea89c-5413-42ca-bd5e-7c6604a3c84a"></img></p>

내용은 편하게 반말로 쓰겠습니다.
## 문제 상황
아티스트의 앨범은 여러 고객이 동일한 상품을 구매하는 경우가 많다.   
![image](https://github.com/ejoongseok/blog/assets/99948743/7e9ea6ee-88a3-4860-85ab-14d07cc1bf58)

그렇기 때문에 물류센터에서는 서로 다른 고객의 같은 상품을 빠르고 효율적으로 출고하는 것이 중요하다.   
당시 나는 물류팀에서 출고의 효율화를 위한 기능을 개발하고 있었다.

기능 개발 이후 오픈 초기에는 한 번에 처리하는 작업량이 수십 건 정도로, 하루 작업량에 비해 1%도 되지 않는 수준이었다.   
해당 작업은 하나의 트랜잭션으로 묶여 있었지만 문제없이 동작했다.

## 문제 발생
문제는 사용량이 늘어나면서 발생했다.   
신규 앨범 발매나 특판 이벤트가 있을 때는 데이터가 많아 트랜잭션이 커밋되기까지 30분 이상 걸리는 경우가 생겨났다.   
오래 걸리는 것도 문제였지만, 더 큰 문제는 중간에 데드락이 발생해 작업이 실패하는 것이었다.   
이유는 출고 작업 중 발생하는 상품 재고 업데이트 쿼리가 대량으로 이루어지면서 데드락이 걸리는 것이었다.  

## 해결 시도
### 첫 번째 시도: 트랜잭션 범위 축소  
첫 번째로 시도한 방법은 트랜잭션의 범위를 좁히는 것이었다.   
서비스 메소드에 걸려 있던 트랜잭션의 범위를 데이터를 저장하는 마지막 부분으로 옮기는 방식이었다.   
```
@Transactional
complete() {
  // select
  // logic
  // save
}

complete() {
  // select
  // logic
  // save @Transactional
}
```
트랜잭션 유지 시간이 줄어들었지만, 여전히 데드락이 발생하고 있었다.  

### 두 번째 시도: 개별 트랜잭션으로 분리
두 번째로 시도한 방법은 모든 작업을 완료한 뒤 한 번에 커밋하는 대신, 각 주문별로 트랜잭션을 분리하는 것이었다.   
이 방법이 가능했던 이유는 해당 작업을 단일 트랜잭션으로 유지할 필요가 없다고 결론이 났기 때문이다.  

```
complete() {
  for (data : dataList) {
    process(data) <- @Transactional
  }
}
```

트랜잭션을 분리했지만, 여전히 데이터가 많을 때는 데드락으로 요청이 실패해 여러 번의 재시도를 거쳐야 했다.   
그래도 재시도할 때마다 처리해야 할 데이터가 줄어들어 작업을 끝낼 수 있었다.   
불편하지만 기능은 사용 가능했기에 작업에 소요되는 시간을 줄이는 것이 다음 목표였다.  

### 세 번째 시도: 병렬 처리
작업에 소요되는 시간을 줄이기 위해 당장 떠올린 방법은 대량의 데이터를 백엔드에서 여러 개의 스레드로 분산해 병렬 처리를 하는 것이었다.   
그러나 멀티 스레드로 분산 처리하는 것은 복잡도가 올라가고 버그를 찾기도 어려우며 변경하기도 어려운 일이었다.   
또한, 특정 인스턴스에 부하가 높아져 시스템이 불안정해지는 문제도 있었다.  

어떻게 하면 이 문제를 쉽고 효율적으로 해결할 수 있을까 고민하던 중 팀장님이 좋은 아이디어를 제시해 주셨다.   
프론트엔드에서 병렬로 요청을 보내는 것이다.   
자바스크립트 라이브러리에는 병렬로 요청을 보내면서 초당 n개로 제어할 수 있는 다양한 라이브러리가 있었고,  
프론트에서 요청을 보내야 여러 백엔드 인스턴스에 부하가 분산될 수 있었다.  

프론트엔드로 병렬 요청을 위임하면 백엔드 로직의 복잡도도 감소하고 멀티스레드를 사용할 때 고민해야 할 문제 역시 자연스럽게 해결할 수 있었다.   
역시 accidental complexity(우발적 복잡성)는 코어에서 최대한 멀리 밀어내야 한다는 생각이 들었다.

작업에 소요되는 시간은 줄어들었으나, 데드락이 발생해 요청이 실패할때마다 재시도를 해야 하는 문제는 아직 남아 있었다.   
출고는 복잡한 프로세스로 이루어져 있어서, 요청 하나를 처리하는 데 길게는 3초가 넘게 걸리는 경우도 있었다.   
하지만 지금까지의 개선으로도 만족스러운 성과였다.

## 배운 점
프론트엔드에서 병렬 요청을 보내는 방식으로 백엔드 로직의 복잡도를 줄이고, 작업에 소요되는 시간을 줄이는 데 성공했다.   
백엔드에서 멀티스레드를 사용하지 않고도 문제를 해결할 수 있었다는 점에서 큰 교훈을 얻었다.   
어떤 문제를 풀기 위해 백엔드에서 멀티스레드를 직접 사용해야 할 일이 있다면 다른 방법은 없는지 고민해봐야 하는 신호일 수도 있을거 같다.  
우발적 복잡성을 코어에서 최대한 멀리 밀어내는 것이 중요하다는 것을 다시 한 번 깨달았다.

## 새로운 문제: 트래픽 급증과 데이터 락
어느 날 커머스에 아티스트 이벤트로 주문이 몰리는 시점에 물류 시스템에서 장애가 발생한다는 알람이 왔다.   
또 다른 날은 물류센터에서 대량 작업을 하는 시간에 주문이 실패한다는 CS가 들어왔다.  

원인은 출고에서 엑세스하는 커머스 데이터였다.   
출고를 할 때 물류의 DB와 커머스의 DB를 업데이트하는 것이 한 트랜잭션으로 이루어져 있는데,   
출고가 완료되면 반드시 커머스의 배송 정보와 상품 재고 같은 게 업데이트 되어야 하기 때문이다.  

<p align="center"><img src="https://github.com/ejoongseok/blog/assets/99948743/1bdc925a-0110-46f2-985e-9722f03d92b0"></img></p>

커머스에 주문 트래픽이 순간적으로 몰리면 물류에서 참조하는 커머스 데이터를 엑세스하는 데 문제가 발생했고,   
반대로 물류에서 대량 작업을 하면 참조하는 커머스 데이터에 부하가 걸리면서 커머스가 영향을 받는 구조였다.  

<p align="center"><img src="https://github.com/ejoongseok/blog/assets/99948743/57b00d6d-1080-4341-a63e-09e9ad953f92"></img></p>

이 문제를 해결하기 위해 물류에서 커머스 데이터에 엑세스하는 것을 격리할 필요가 있었다.

이 내용은 다음 글에서 작성해보도록 하겠습니다.

감사합니다.

## 다음 글
- [2.서비스간 의존성 격리: 트랜잭셔널 아웃박스 패턴](https://github.com/ejoongseok/blog/blob/main/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/2.%EC%84%9C%EB%B9%84%EC%8A%A4%EA%B0%84%20%EC%9D%98%EC%A1%B4%EC%84%B1%20%EA%B2%A9%EB%A6%AC%3A%20%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%94%EB%84%90%20%EC%95%84%EC%9B%83%EB%B0%95%EC%8A%A4%20%ED%8C%A8%ED%84%B4.md)
