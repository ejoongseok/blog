# 서비스간 의존성 격리: 트랜잭셔널 아웃박스 패턴

2024년도 1분기에 있었던 물류와 커머스 서비스간 의존성 격리를 주제로 작업한 경험을 적어보도록 하겠습니다.

2023년 동안 케타포 시스템은 많은 개선이 이루어졌지만,   
여전히 해결되지 않은 문제 중 하나는 물류와 커머스 시스템 간의 높은 의존성으로 인해 한쪽의 트래픽이 높아질 때 다른 쪽에서 장애가 발생하는 문제가 있었다.  
이를 해결하기 위해 각 서비스 간의 의존성을 격리해야 했다.  

<p align="center"><img src="https://github.com/ejoongseok/blog/assets/99948743/38762c67-ec50-4743-8603-072cabad5553"></img></p>

## 이전 글
- [1.대량 상품 출고 데이터 처리](https://github.com/ejoongseok/blog/blob/main/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/1.%EB%8C%80%EB%9F%89%20%EC%83%81%ED%92%88%20%EC%B6%9C%EA%B3%A0%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%B2%98%EB%A6%AC.md)


## 문제 상황
2024년도 1분기 중반 나는 물류팀에서 커머스팀으로 팀을 이동했다.     
팀 이동 후 첫 번째 과제는 물류 시스템에 포함된 커머스 데이터 변경 로직을 분리하는 것이었다.     
물류 시스템에 커머스 변경 로직이 혼재되어 있기 때문에 로직이 복잡하고 처리 시간이 오래 걸렸다.     
성능 개선, 서비스 안정화, 복잡도 감소를 위해 서비스 간 역할을 명확히 분리할 필요가 있었다.  

## 개선 방법
### 트랜잭셔널 아웃박스 패턴
팀에서는 물류와 커머스의 데이터 변경을 격리하기 위해 트랜잭셔널 아웃박스 패턴을 채택했다. 이 패턴을 선택한 이유는 다음과 같다.    
-  **트랜잭션 분리**: 물류와 커머스의 데이터 변경이 한 트랜잭션으로 이루어져있던 것을 쉽게 분리할 수 있었다.    
-  **Eventual Consistency(최종 일관성) 보장**: 물류의 작업이 완료되면 커머스의 데이터 변경이 반드시 이루어져야 하지만, 완전히 실시간으로 동기화할 필요는 없었다. 너무 늦지 않게 최종 일관성만 지키면 되었다.  
-  **단순한 패턴**: 패턴 자체가 단순하여 러닝 커브가 높지 않았다.
-  **우발적 복잡성 제거**: 메시지가 발행됐는데 출고가 실패한다던지, 출고가 성공했는데 메시지가 발행이 안된다던지 하는 우발적인 복잡성을 제거할 수 있다.

<p align="center">
  <img src="https://github.com/ejoongseok/blog/assets/99948743/4e9bcfe8-0359-48b4-85e3-5142ab48a27b"></img>
  https://microservices.io/patterns/data/transactional-outbox.html
</p>


### 구현 방법
1. 물류 시스템에서 작업이 완료 될 때 아웃박스 테이블에도 이벤트를 저장한다.   
2. Debezium CDC가 DB의 트랜잭션 로그를 읽어 아웃박스 테이블에 새로 생성된 이벤트에 대해 Kafka 브로커로 메시지를 발행한다.   
3. Kafka 리스너는 이 메시지를 읽어 커머스 데이터를 변경한다.  

<p align="center">
  <img src="https://github.com/ejoongseok/blog/assets/99948743/6b62987f-904a-48e1-a51b-07db2527537e"></img>
  https://medium.com/yotpoengineering/outbox-with-debezium-and-kafka-the-hidden-challenges-998c00487ae4
</p>

Kafka를 선택한 이유는 다음과 같았다.  
- **풍부한 참고 사례**: Debezium과 Kafka를 조합한 트랜잭셔널 아웃박스 패턴 사례가 많아 참고하기 쉬웠다.  
- **팬아웃 용이성**: 물류에서는 여러 도메인에 이벤트를 보내야 하는 경우가 있는데, Kafka는 이를 팬아웃하기에 용이했다.  
- **무한한 보관 기간**: Kafka는 메시지가 유실되지 않고 보관할 수 있어 다양한 용도로 활용할 수 있다. (애플리케이션 로직과 상관없이 분석용으로도 사용 가능)  

이외에도 여러 합리적인 이유들이 있었지만,   
해당 아이디어와 카프카 설정은 동료들이 해주신 부분이어서 나는 깊게 알지 못하여 여기까지만 적도록 하겠다.

### 작업 과정
#### 이벤트 페이로드 정의
첫 번째 작업은 이벤트 리스너가 사용할 아웃박스 이벤트의 페이로드를 정의하는 것이었다.  
``` java
public interface Event<T> {
    T payload();
    String type();
    int version();
    UUID id();
    LocalDateTime timestamp();
}
```
#### 커머스 로직 분리(feat. lift & shift)
다음으로는 물류 시스템에 있던 커머스 로직을 Kafka 리스너가 있는 새로운 서비스로 옮기는 작업을 진행했다.   
로직을 옮긴 뒤 생각지 못한 문제가 발생했을 때 언제든 롤백 가능 하도록 피처 플래그를 추가해 장애 상황을 대비했다.
``` java
public void process() {
  if(flag) {
    아웃박스 테이블 저장();
    return;
  } 
  분리 전 기존 로직();
}

```

커머스 로직을 분리하기 전에 리팩터링을 진행하려 했으나, 커머스 변경 로직은 레거시 로직이었기 때문에 파악하고 개선하는데 시간이 오래걸리고 어려운 일이었다.
따라서, lift & shift 방식으로 옮기기로 했다.   
<p align="center">
  <img src="https://github.com/ejoongseok/blog/assets/99948743/f30a8443-b0ad-4f15-8aed-2749c16b7591"></img>
  https://www.suntechnologies.com/blogs/understanding-lift-and-shift-cloud-migration-best-practices-to-follow/
</p>

기존 로직이 이미 잘 동작하고 검증된 상태였기 때문에 옮기면서 발생할 수 있는 문제를 최소화 하기 위한 방법이었다.  
리팩터링 한 뒤 로직을 옮기면 문제가 발생했을 때 리팩터링하면서 생긴 문제인지 연동의 문제인지 원인을 파악하기 어렵고,   
수정된 코드를 다시 검증해야 하는 문제가 있었다.   
그래서 lift & shift로 옮기고, 잘 운영이 된다면 이후에 변경이 필요할 때 리팩터링을 진행하기로 했다.  

#### 페어 프로그래밍
새로운 서비스에 코드를 작성하는 작업은 동료와 페어 프로그래밍으로 진행했다.   
페어프로그래밍을 통해 처음 생각보다 더 좋은 방법으로 구현할 수 있었다.   

페어를 할 때 Outside-In 방식으로 접근했는데, 이렇게 하면 외부의 인터페이스부터 생각하다보니 구체적인 내부 구현의 고민에 대한 인터럽트가 없어서 좋았다.   
종종 페어 중 디테일에 매몰되는 경우가 많은데 이 부분을 경계하면 좋은거같다.    

**Outside-In 방식**
<p align="center">
  <img src="https://github.com/ejoongseok/blog/assets/99948743/2ef252d4-8235-48e9-971c-e21189807e87"></img>
</p>


그리고 작은 단위로 여러번 진행했는데 작은 단위로 하다보니 목표가 구체적이고 명확하게 정해져있어서 좋았다.  
페어프로그래밍이 끝나면 바로 회고 글을 작성했다.   
회고를 작성한 이유는 당사자 외에는 서로가 배운것이 잘 공유가 되지 않는다고 느꼈기 때문이다.  

회고 글을 작성해서 사내에 공유하면 당사자가 아닌 사람들도 간접적으로 경험을 할 수 있고,   
페어를 진행하면서 어떤점이 좋았고 어떤점이 아쉬웠는지 정리를 할 수 있어서 다음 페어를 할 때 참고해서 더 나은 방향으로 진행 할 수 있게 도와준다.    

**페어프로그래밍 이후 당시에 작성했던 회고 일부**
<p align="center">
  <img src="https://github.com/ejoongseok/blog-stage/assets/99948743/3dc9e3da-7641-4986-88e8-86a3b5b1d7a0"></img>
</p>

#### 통합 테스트
연동 과정에서 발생할 수 있는 문제를 사전에 방지하기 위해 통합 테스트를 작성했다.   
통합 테스트를 통해 단위 테스트로 확인하기 어려운 Spring 연동 오류를 애플리케이션 실행 전에 해결할 수 있었다.   
통합 테스트를 수행하면서 SQL이 옮기기전과 동일하게 생성되는지 diff를 확인해가며 검증했다.    

그럼에도 불구하고 직접 실행해 확인했을때 서비스 간 payload 매핑 과정에서 serialization/deserialization 오류가 발생했다.   
이러한 오류를 방지하기 위해 최종적으로 애플리케이션을 직접 실행해 기능이 잘 동작하는지 확인하는 습관이 필요하다.  

#### 부하 테스트
연동을 완료한 뒤, 몇 가지 확인을 위해 부하 테스트를 진행했다.   

- **첫번째 부하테스트**
  - **테스트 목적**
    - **메시지 유실 및 오류 확인**: 트랜잭셔널 아웃박스 패턴을 적용한 뒤 Kafka를 통해 메시지를 pub/sub 할 때 메시지 유실이나 오류가 없는지 확인했다.   
    - **kafka 지표 확인**: 아웃박스 테이블에 최대 허용 가능한 성능으로 insert를 했을 때 Kafka의 성능 지표를 측정했다.   
    - **최종 일관성 latency 확인**: 아웃박스 테이블에 이벤트를 저장하고 Kafka 리스너가 커머스 데이터를 처리하는 데까지 걸리는 지연 시간을 확인했다.  

  - **테스트 방법**  
 아웃박스 테이블에 insert만 하는 API를 만든 뒤 테스터가 설정한 TPS 만큼 요청을 보낸다.
  - **테스트 결과**  
 메시지 유실이나 오류 없이 준실시간에 가깝게 처리되었고, Kafka의 성능 지표도 안정적으로 처리되었다.

- **두번째 부하테스트**
  - **테스트 목적**
    - **상용 카프카 스펙 결정**: 상용 카프카의 스펙을 결정하기 위해 카프카의 임계점까지 메시지를 발행한다.  

  - **테스트 방법**  
아웃박스 테이블을 통하지 않고 kafkaTemplate을 사용해서 메시지를 직접 발행했다.   
인스턴스별로 무한루프를 돌며 특정 토픽에 메시지를 발행하는 방법이었는데, 인스턴스를 최대 24개까지늘려서 초당 10만개의 메시지를 발행할 수 있었다.

  - **테스트 결과**  
5만 TPS에서 latency는 100ms 미만으로 높은 안정성을 보여줬다.  
그 이상 넘어가면 latency가 점점 길어지는 모습을 보였다. 그 외에도 트래픽이 몰릴때 컨슈머 수를 늘려도 기대한대로 바로바로 latency는 줄어들거나 하지 않았다.   

- **테스트 환경 스펙**
```
퍼블리셔
- 인스턴스 24개
- cpu 4000m
- memory 4000Mi

컨슈머 
- 인스턴스 3개
- cpu 2000m
- memory 1500Mi

브로커
- kafka.m5.large
```

## 성과
트랜잭셔널 아웃박스 패턴을 적용한 후, 물류 작업은 더이상 커머스에 의해 지연되거나 오류가 발생하지 않았다. 성능도 최소 50% 이상 개선되었다.     
또한, 물류의 대량 작업으로 인해 이벤트가 순간적으로 많이 쌓여도 컨슈머가 커머스 데이터를 안정적으로 처리할 수 있도록 RateLimiter를 적용해 안정성을 확보했다.    
만약 리스너가 우발적인 상황에 의해 실패하더라도 retry topic에서 재처리를 진행했고, 최종적으로 데드레터 토픽에 담기기 때문에 원인을 분석하고 수동 또는 자동으로 처리할 수 있었다.    
<p align="center">
  <img src="https://github.com/ejoongseok/blog/assets/99948743/a2b9d775-68f7-4d85-803e-9f58d0e12c3b"></img>
  https://alexandrecastro.tech/post/kafka-retries-go/
</p>

## 결론
결과적으로 물류와 커머스는 더 이상 각 서비스의 부하가 상대 서비스에 영향을 주지 않게 되었고, 높은 수준의 성능 개선과 안정성을 확보 할 수 있게 되었다.    
인프라 수준에서의 DIP를 적용한셈이라고 볼 수 있을거같다.  

## 다음 과제
그 다음으로는 커머스에 주문 트래픽이 몰릴때 서비스가 안정적으로 운용될 수 있도록 주문 프로세스를 개선해야했다. 

이 내용은 다음 글에서 작성해보도록 하겠습니다.

감사합니다.

## 다음 글
- [3.주문 개선하기: 시퀀스 테이블 페이드아웃]()
